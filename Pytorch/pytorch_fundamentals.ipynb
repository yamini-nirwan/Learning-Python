{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734d1a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # True if PyTorch can use GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895fe79",
   "metadata": {},
   "source": [
    "**What is PyTorch?**\n",
    "- most popular research deep learning framework\n",
    "- write fast deep learning code in Python (able to run on a GPU/many GPUs) \n",
    "- Able to access many pre-built deep learning models (Torch Hub/ torchdivisions.models)\n",
    "- whole stack: preprocess data, model data, deploy model in your application/cloud\n",
    "- originally designed and used in-house by Facebook/Meta (now open-source and used by companies such as Tesla, Microsoft, OpenAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc44c2",
   "metadata": {},
   "source": [
    "**Tensors (like NumPy arrays, but with GPU acceleration).**\n",
    "\n",
    "Example: Running physics simulations or mathematical optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1830bb",
   "metadata": {},
   "source": [
    "Creating an empty Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20172e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 3) # Creates a 2x3 matrix with uninitialized values\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "391e17c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2162, 0.6979, 0.5876],\n",
      "        [0.7250, 0.8474, 0.8090]])\n",
      "torch.float32\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3, dtype=torch.float32) #float32 means 32-bit floating point \n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(x.size())  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b5f29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0427, 0.9045, 0.0266],\n",
      "        [0.2643, 0.3797, 0.5388]])\n",
      "tensor([[0.0405, 0.9960, 0.8178],\n",
      "        [0.7977, 0.2083, 0.4024]])\n",
      "tensor([[0.0832, 1.9005, 0.8444],\n",
      "        [1.0620, 0.5880, 0.9412]])\n",
      "tensor([[0.0832, 1.9005, 0.8444],\n",
      "        [1.0620, 0.5880, 0.9412]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "y = torch.rand(2, 3)\n",
    "print(x)\n",
    "print(y)\n",
    "z = x + y\n",
    "z = torch.add(x, y)  # another way to add\n",
    "print(z)\n",
    "\n",
    "y.add_(x)  # in-place addition\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ddf5210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4438, 0.6561, 0.0963],\n",
      "        [0.7901, 0.4594, 0.3508]])\n",
      "tensor([[0.1286, 0.2632, 0.9576],\n",
      "        [0.0715, 0.2947, 0.0384]])\n",
      "tensor([[ 0.3152,  0.3929, -0.8614],\n",
      "        [ 0.7186,  0.1647,  0.3125]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "y = torch.rand(2, 3)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "z = x - y\n",
    "z = torch.sub(x, y)  # another way to subtract\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b70d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3300, 0.4379, 0.1028],\n",
      "        [0.2261, 0.7465, 0.4833]])\n",
      "tensor([[0.2588, 0.5717, 0.1556],\n",
      "        [0.1012, 0.8391, 0.2250]])\n",
      "tensor([[0.0854, 0.2503, 0.0160],\n",
      "        [0.0229, 0.6264, 0.1087]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "y = torch.rand(2, 3)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "z = x * y\n",
    "z = torch.mul(x, y)  # another way to multiply\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b4bca2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9417, 0.5666, 0.3091],\n",
      "        [0.2304, 0.8315, 0.1816]])\n",
      "tensor([[0.7497, 0.3809, 0.0585],\n",
      "        [0.3629, 0.6711, 0.4536]])\n",
      "tensor([[1.2562, 1.4876, 5.2819],\n",
      "        [0.6349, 1.2390, 0.4004]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "y = torch.rand(2, 3)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "z = x * y\n",
    "z = torch.div(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9967bf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2029, 0.2472, 0.3814],\n",
      "        [0.1498, 0.7939, 0.2005]])\n",
      "tensor([0.2472, 0.7939])\n",
      "tensor([0.1498, 0.7939, 0.2005])\n",
      "0.7939461469650269\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "\n",
    "print(x)\n",
    "print(x[:, 1])  #all rows, column 1\n",
    "print(x[1, :])  #row 1, all columns\n",
    "print(x[1, 1].item())  #get the value as a standard Python number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0373cab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar tensors\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "120fb3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d26afab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get tensor back as a Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7af2f03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vector\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "791c06e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42a425a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape #2 elements in vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41ed9274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix\n",
    "matrix = torch.tensor([[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60e9ffde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d26cb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape #3 number of rows, 3 number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21586aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]],\n",
       "\n",
       "        [[19, 20, 21],\n",
       "         [22, 23, 24],\n",
       "         [25, 26, 27],\n",
       "         [28, 29, 30]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor\n",
    "tensor = torch.tensor([[[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9],\n",
    "                        [10,11,12]],\n",
    "                       [[19,20,21],\n",
    "                        [22,23,24],\n",
    "                        [25,26,27],\n",
    "                        [28,29,30]]])\n",
    "tensor   #most of the tensors we don't write by hand like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47cf5332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim #rows, columns and a layer, so total 3 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa088705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape \n",
    "#2 layers and each matrix has 3 rows and 3 columns \n",
    "#therefore shape shows first the number of layers, then number of rows in the matrix and then the number of elements in each row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274b04b6",
   "metadata": {},
   "source": [
    "**Random Tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed28575",
   "metadata": {},
   "source": [
    "Random tensors are important because the way many neural networks learn is that they start with tensors full of random\n",
    "numbers and then adjust those random numbers to better represent the data.\n",
    "\n",
    "'Start with random numbers ==> look at data ==> update random numbers ==> look at data ==> update random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6250cd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7480, 0.6417, 0.6538, 0.6774],\n",
       "        [0.8526, 0.7786, 0.9433, 0.5988],\n",
       "        [0.0562, 0.7834, 0.9179, 0.9912]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a random tensor of size (3,4)\n",
    "random_tensor = torch.rand(3, 4) #creates a tensor of 3 rows and 4 columns with random values between 0 and 1\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76ea65be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0912759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6927, 0.2978, 0.0880, 0.7969],\n",
       "         [0.1174, 0.3294, 0.5533, 0.9187],\n",
       "         [0.0212, 0.1811, 0.5262, 0.8606]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(1, 3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f88027e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1725e39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size = (3, 224, 224)) #color channels (RGB), height, width\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0154445f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a tensor of all zeros\n",
    "zeros = torch.zeros (size = (3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f85db8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a tensor of all ones\n",
    "ones = torch.ones (size = (3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbc08b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a0dfdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a range of tensors and tensors-like\n",
    "one_to_ten = torch.arange(0, 10)  #similar to python's range function\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54e0d070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(start = 1, end = 11, step = 1 )\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac984d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating tensors like\n",
    "ten_zeros = torch.zeros_like(input = one_to_ten)  #creates a tensor of zeros with the same shape as one_to_ten\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d6ef4e",
   "metadata": {},
   "source": [
    "**Tensor Datatypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f1f09cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                                     dtype = None, #what dtype is this tensor\n",
    "                                     device = None, #what device is this tensor on\n",
    "                                     requires_grad = False) #whether or not to track gradients with this tensor operations\n",
    "float_32_tensor\n",
    "\n",
    "                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f811803f",
   "metadata": {},
   "source": [
    "**What is meant by 32-bit floatung point, 16-bit floating point and 64-bit floating point?**\n",
    "- 32-bit is sigle precision (default)\n",
    "- 16-bit is half precision\n",
    "- These numbers represent how much detail a single numbers is stored in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf398410",
   "metadata": {},
   "source": [
    "**NOTE:** Tensor datatypes is one of the 3 big errors you'll run with Pytorch and deep learning:\n",
    "1. Tensors not right datatypes\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6902de6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "401a0ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert float32 tensor to float16 tensor (reduced precision, half precision)\n",
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9de65424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed8ea78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype = torch.long) #long means int64\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06b2003d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb6c07",
   "metadata": {},
   "source": [
    "**Getting Information from Tensors (Tensors attributes)**\n",
    "1. Tensors not right datatypes - to do get datatype from a tensor, can use tensor.dtype\n",
    "2. Tensors not right shape - to get shape from a tensor, can use tensor.shape\n",
    "3. Tensors not on the right device- to get device from a tensor, can use tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "492d0451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8068, 0.2817, 0.6833, 0.9806],\n",
       "        [0.6558, 0.9452, 0.6593, 0.0701],\n",
       "        [0.4980, 0.7698, 0.1036, 0.7358]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3c9ea12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([3, 4]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.size (), some_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d9c75bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8068, 0.2817, 0.6833, 0.9806],\n",
      "        [0.6558, 0.9452, 0.6593, 0.0701],\n",
      "        [0.4980, 0.7698, 0.1036, 0.7358]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "##find out the details about some tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52e86d7",
   "metadata": {},
   "source": [
    "##Manipulating tensors (tensor operations)\n",
    "\n",
    "Tensor operations include\n",
    "-  Addition\n",
    "- Substraction\n",
    "- Multiplication (element wise)\n",
    "- Division\n",
    "- Matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d3387a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbdb5714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiply tensor by 10\n",
    "tensor *10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3d12f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c451737f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subtract tensor by 10\n",
    "tensor-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e140bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pytorch built-in functions\n",
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ecb9078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeed957",
   "metadata": {},
   "source": [
    "**Matrix Multiplication**\n",
    "Two main ways of performing multiplication in neural networks and deep learning:\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication\n",
    "\n",
    "There are two main rules that performing matrix multiplication needs to satisfy: \n",
    "1. The **inner dimensions** must match:\n",
    "e.g. (3, 2) @ (3, 2) won't work\n",
    "     (2, 3) @ (3, 2) will work\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cf95b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "##Element wise multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d861c50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix multiplication (basically the dot product using torch function)\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6811c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can also use the '@' symbol for matrix multiplication, though not recommended\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1eb3b3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "#Calculate the dot product using a for loop\n",
    "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
    "value = 0\n",
    "for i in  range(len(tensor)):\n",
    "                value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06e2e8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                                     dtype = None, #what dtype is this tensor\n",
    "                                     device = None, #what device is this tensor on\n",
    "                                     requires_grad = False) #whether or not to track gradients with this tensor operations\n",
    "                                     \n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e6831",
   "metadata": {},
   "source": [
    "**One of the most common errors in deep learning (shape errors)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64263586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shapes need to be in the right place\n",
    "tensor_A = torch.tensor ([[1, 2], \n",
    "                          [3, 4],\n",
    "                          [5, 6]], dtype = torch.float32)\n",
    "tensor_B =  torch.tensor([[7, 10],\n",
    "                          [8, 11],\n",
    "                          [9, 12]], dtype = torch.float32)\n",
    "#here matrix multiplication will give an error\n",
    "#Inner dimensions of the matrices need to match\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1271d36a",
   "metadata": {},
   "source": [
    "**Transpose** switches the dimensions of a given tensor\n",
    "In Pytorch:\n",
    "- **torch.transpose(input, dim0, dim1)** : where *input* is the desired tensor to transpose and *dim0* and *dim1* are the dimensions to be swaped\n",
    "- **tensor.T** : where *tensor* is the desired tensor to transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc6e8623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#Transpose tensor_B\n",
    "print(tensor_B.T)\n",
    "print(tensor_B.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "509e8553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3])\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n"
     ]
    }
   ],
   "source": [
    "#Transpose tensors and multiply\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape}\") #inner dimensions match\n",
    "multiplication_output = torch.matmul (tensor_A, tensor_B.T)\n",
    "print(multiplication_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e515779",
   "metadata": {},
   "source": [
    "**Neural networks are full of matrix multiplications and dot products**\n",
    "\n",
    " The *torch.nn.Linear()* module, also knows as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input x and a weights matrix A.\n",
    "\n",
    "\n",
    "Where: \n",
    " $$ y = x.A^T + b $$\n",
    "\n",
    "x is the input to the layer (deep learning is a stack of layers like torch.nn.Linear() and others on top of each other).\n",
    "\n",
    "A is the weights matrix created by the layer, this starts out as random numbers that get adjusted as a neural network learns to better represent patterns in the data (notice the \"T\", that's because the weights matrix gets transposed).\n",
    "\n",
    "**Note**: You might also often see W or another letter like X used to showcase the weights matrix.\n",
    "\n",
    "b is the bias term used to slightly offset the weights and inputs.\n",
    "y is the output (a manipulation of the input in the hopes to discover patterns in it).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac4aed",
   "metadata": {},
   "source": [
    "**Finding the min, max, mean, sum, etc (aggregation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bbf5a323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "417b957c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "#Using torch built-in functions, these are more commonly used\n",
    "print(f\"Minimum: {torch.min(x)}\")\n",
    "print(f\"Maximum: {torch.max(x)}\")\n",
    "print(f\"Mean: {torch.mean(x.float())}\")  #convert to float first #won't work without float datatype\n",
    "print(f\"Sum: {torch.sum(x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "254a384d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "#Other ways\n",
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\")\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92665480",
   "metadata": {},
   "source": [
    "**Positional min/max**\n",
    "\n",
    "To find the index of a tensor where the max or minimum occurs with *torch.arg(max)* and *torch.argmin()* respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60e72507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index of minimum value: 0\n",
      "Index of maximum value: 9\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "#Returns index of min and max\n",
    "print(f\"Index of minimum value: {torch.argmin(tensor)}\")\n",
    "print(f\"Index of maximum value: {torch.argmax(tensor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788770d6",
   "metadata": {},
   "source": [
    "**Change the tensor datatype**\n",
    "\n",
    "A common issue with deep learning operations is having your tensors in different datatypes.\n",
    "\n",
    "If one tensor is in torch.float64 and another is in torch.float32, you might run into some errors.\n",
    "\n",
    "Datatypes of tensors can be changed using **torch.Tensor.type(dtype=None)** where the dtype parameter is the datatype you'd like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9f4a64f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0., 10., 20., 30., 40., 50., 60., 70., 80., 90.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_default = torch.arange(0., 100., 10.)\n",
    "print(tensor_default)\n",
    "tensor_default.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ca281a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0., 10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the datatype to float16\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86e92a",
   "metadata": {},
   "source": [
    "**Note**: Different datatypes can be confusing to begin with. But think of it like this, the lower the number (e.g. 32, 16, 8), the less precise a computer stores the value. And with a lower amount of storage, this generally results in faster computation and a smaller overall model. Mobile-based neural networks often operate with 8-bit integers, smaller and faster to run but less accurate than their float32 counterparts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03b271b",
   "metadata": {},
   "source": [
    "**Reshaping, stacking, squeezing and unsqueezing**\n",
    "\n",
    "To reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
    "\n",
    "torch.reshape(input, shape):\tReshapes input to shape (if compatible), can also use torch.Tensor.reshape().\n",
    "\n",
    "Tensor.view(shape):\tReturns a view of the original tensor in a different shape but shares the same data as the original tensor.\n",
    "\n",
    "torch.stack(tensors, dim=0):\tConcatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.\n",
    "\n",
    "torch.squeeze(input):\tSqueezes input to remove all the dimenions with value 1.\n",
    "\n",
    "torch.unsqueeze(input, dim):\tReturns input with a dimension value of 1 added at dim.\n",
    "\n",
    "torch.permute(input, dims):\tReturns a view of the original input with its dimensions permuted (rearranged) to dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78e4beda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf1a2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add an extra dimension with torch.reshape()\n",
    "x_reshaped = x.reshape(1, 9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca34d659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change view (keeps same data as original but changes view)\n",
    "z = x.view(1, 9)\n",
    "z, z.shape\n",
    "#Remember though, changing the view of a tensor with torch.view() really only creates a new view of the same tensor.\n",
    "#So changing the view changes the original tensor too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12a33c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changing z changes x\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfc1249d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " torch.Size([5, 9]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stacking a new tensor on top of itself five times\n",
    "x_stacked = torch.stack([x]*5, dim=0)\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bda679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 5., 5., 5., 5.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [3., 3., 3., 3., 3.],\n",
       "         [4., 4., 4., 4., 4.],\n",
       "         [5., 5., 5., 5., 5.],\n",
       "         [6., 6., 6., 6., 6.],\n",
       "         [7., 7., 7., 7., 7.],\n",
       "         [8., 8., 8., 8., 8.],\n",
       "         [9., 9., 9., 9., 9.]]),\n",
       " torch.Size([9, 5]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stacking a new tensor on top of itself five times\n",
    "x_stacked = torch.stack([x]*5, dim=1) \n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74fef0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous shape: torch.Size([1, 9])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "#torch.squeeze() (I remember this as squeezing the tensor to only have dimensions over 1).\n",
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2274f425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([9])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "#torch.unsqueeze() to add a dimension value of 1 at a specific index.\n",
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4724234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New tensor: tensor([[5.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "New shape: torch.Size([9, 1])\n"
     ]
    }
   ],
   "source": [
    "#torch.permute(input, dims), where the input gets turned into a view with the new dims.\n",
    "x_permuted = x_unsqueezed.permute(1, 0) #swap dimensions at index 1 with index 0 i.e. from (1,9) to (9,1) \n",
    "print(f\"\\nNew tensor: {x_permuted}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45adc9f1",
   "metadata": {},
   "source": [
    "**Indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e98bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
